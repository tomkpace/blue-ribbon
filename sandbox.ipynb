{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd063d0a0a306d17f9618fcd2df71f8943413e3c03229e5631c7d32ac919a8133cf",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from relation_extractor import RelationExtractor\n",
    "from nlp import nlp, ner, process_ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(\"raw_data/movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I noticed that there were duplicate entries for certain \n",
    "movies that were released in separate origins.  This \n",
    "removes those duplicates so we can use the rotten_tomatoes_link\n",
    "as the primary index of the data.\n",
    "\"\"\"\n",
    "duplicates = movie_data.groupby(\"rotten_tomatoes_link\").count() \\\n",
    "    .loc[np.any(movie_data.groupby(\"rotten_tomatoes_link\") \\\n",
    "    .count() > 1, axis=1)].index\n",
    "\n",
    "dup_indices = movie_data.loc[(movie_data[\"rotten_tomatoes_link\"].isin(duplicates)) & \\\n",
    "    (movie_data[\"Origin/Ethnicity\"] != \"American\")].index\n",
    "\n",
    "movie_data = movie_data.loc[~movie_data.index.isin(dup_indices)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_column(input_df, column_name, new_column_name):\n",
    "    \"\"\"\n",
    "    Function that will expand the string columns that have \n",
    "    values separated by commas.\n",
    "    \"\"\"\n",
    "    df = input_df.copy(deep=True)\n",
    "    exploded_df = df[column_name].astype(str) \\\n",
    "        .apply(lambda x: x.split(\",\")).explode() \\\n",
    "        .to_frame().rename(columns={column_name: new_column_name})\n",
    "    df = df.merge(exploded_df[[new_column_name]], left_index=True, right_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_columns = {\n",
    "    \"genres\": \"genre\",\n",
    "    \"directors\": \"director\",\n",
    "    \"authors\": \"author\",\n",
    "    \"actors\": \"actor\"\n",
    "}\n",
    "\n",
    "exploded_dfs = {}\n",
    "for c in explode_columns.keys():\n",
    "    exploded_dfs[c] = explode_column(movie_data, c, explode_columns[c])\n",
    "for c in exploded_dfs.keys():\n",
    "    movie_data = movie_data.merge(\n",
    "        exploded_dfs[c][[explode_columns[c]]], left_index=True, right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {\n",
    "    \"rotten_tomatoes_link\":\"entity_id\",\n",
    "    \"Title\":\"has title\",\n",
    "    \"director\":\"directed by\",\n",
    "    \"author\":\"authored by\",\n",
    "    \"actor\":\"featured actor\",\n",
    "    \"genre\":\"has genre\",\n",
    "    \"Release Year\":\"released on\",\n",
    "    \"production_company\":\"produced by\",\n",
    "}\n",
    "relations = []\n",
    "for r in relation_dict:\n",
    "    relations.append(relation_dict[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df = movie_data.rename(columns=relation_dict)[relations] \\\n",
    "    .drop_duplicates() \\\n",
    "    .reset_index(drop=True)\n",
    "known_df = tabular_df.melt(id_vars=\"entity_id\", value_vars=['has title', 'directed by', 'authored by', 'featured actor',\n",
    "       'has genre', 'released on', 'produced by']).drop_duplicates().reset_index(drop=True).rename(columns={\"variable\":\"relation\"})\n",
    "known_df.to_csv(\"data/known_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df.to_csv(\"data/tabular_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_review_df = pd.read_csv(\"raw_data/rotten_tomatoes_critic_reviews.csv\")\n",
    "raw_review_df = raw_review_df.loc[raw_review_df[\"review_content\"].astype(str) != 'nan'].reset_index(drop=True)\n",
    "raw_review_df.to_csv(\"data/raw_review_df.csv\")\n",
    "review_df = raw_review_df[[\"rotten_tomatoes_link\", \"review_content\"]] \\\n",
    "    .rename(columns={\"rotten_tomatoes_link\": \"entity_id\", \"review_content\": \"text\"})\n",
    "review_df.to_csv(\"data/review_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv(\"data/review_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "def generate_theme_df(movie_data):\n",
    "    theme_df = movie_data[[\"rotten_tomatoes_link\", \"Title\", \"genre\", \"Plot\"]] \\\n",
    "        .drop_duplicates().reset_index(drop=True)\n",
    "    genres = theme_df[\"genre\"].unique()\n",
    "    theme_df[\"indicator\"] = 1\n",
    "    theme_pivot = theme_df \\\n",
    "        .pivot(index=\"rotten_tomatoes_link\", columns=\"genre\", values=\"indicator\") \\\n",
    "        .fillna(0).reset_index()\n",
    "    theme_df = theme_df[[\"rotten_tomatoes_link\", \"Title\", \"Plot\"]] \\\n",
    "        .drop_duplicates().merge(theme_pivot, on=\"rotten_tomatoes_link\") \\\n",
    "        .reset_index(drop=True)\n",
    "    return theme_df\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,3))\n",
    "clf = ExtraTreesClassifier()\n",
    "X = vectorizer.fit_transform(theme_df[\"Plot\"])\n",
    "clf.fit(X, theme_df[\"Comedy\"])\n",
    "importances = clf.feature_importances_\n",
    "names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv(\"data/review_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For those of us who love Cinema Paradiso, the news that its Italian director Giuseppe Tornatore and his musical soulmate Ennio Morricone were getting back together to do another coming-of-age film, Malena, gave us tantalizing hope. Malena fa\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(1, len(review_df))\n",
    "text = review_df.iloc[i][\"text\"]\n",
    "entity_id = review_df.iloc[i][\"entity_id\"]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"For those of us who love Cinema Paradiso, the news that its Italian director Giuseppe Tornatore and his musical soulmate Ennio Morricone were getting back together to do another coming-of-age film, Malena, gave us tantalizing hope. Malena fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Cinema Paradiso', 'MISC'),\n",
       " ('Italian', 'MISC'),\n",
       " ('Giuseppe Tornatore', 'PER'),\n",
       " ('Ennio Morricone', 'PER'),\n",
       " ('Malena', 'MISC'),\n",
       " ('Malena', 'MISC')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "process_ner_output(ner(\"For those of us who love Cinema Paradiso, the news that its Italian director Giuseppe Tornatore and his musical soulmate Ennio Morricone were getting back together to do another coming-of-age film, Malena, gave us tantalizing hope. Malena fa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('entity_id', 'features', 'Cinema Paradiso')\n('entity_id', 'features', 'Italian')\n('entity_id', 'features', 'Giuseppe Tornatore')\n('entity_id', 'features', 'Ennio Morricone')\n('entity_id', 'features', 'Malena')\n('entity_id', 'features', 'Malena')\n('entity_id', 'has', 'cinema paradiso')\n('entity_id', 'has', 'news')\n('entity_id', 'has', 'italian director')\n('entity_id', 'has', 'giuseppe tornatore')\n('entity_id', 'has', 'musical soulmate')\n('entity_id', 'has', 'ennio morricone')\n('entity_id', 'has', 'age')\n('entity_id', 'has', 'malena')\n('entity_id', 'has', 'hope')\n('entity_id', 'is', 'italian')\n('entity_id', 'is', 'musical')\n('entity_id', 'getting', 'back')\n('entity_id', 'getting', 'together')\n"
     ]
    }
   ],
   "source": [
    "r = RelationExtractor(\"entity_id\", text)\n",
    "for i in r.relations:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('balls', 'is', 'italian'),\n",
       " ('balls', 'is', 'musical'),\n",
       " ('balls', 'getting', 'back'),\n",
       " ('balls', 'getting', 'together')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "\"\"\"\n",
    "def negation_detector(token):\n",
    "    head = token.head\n",
    "    try:\n",
    "        while head.pos_ != \"VERB\":\n",
    "            head = head.head\n",
    "        for token in head.children:\n",
    "            if token.dep_ == \"neg\":\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def verb_extractor(token):\n",
    "    head = token.head\n",
    "    try:\n",
    "        while head.pos_ != \"VERB\":\n",
    "            if head == head.head:\n",
    "                return None\n",
    "            head = head.head\n",
    "        return head.text\n",
    "    except Exception:\n",
    "        return None\n",
    "\"\"\"\n",
    "def extract_ad_relations(entity_id, text):\n",
    "    doc = nlp(text)\n",
    "    relations = []\n",
    "    for t in doc:\n",
    "        if not negation_detector(t):\n",
    "            if t.pos_ in (\"ADJ\"):\n",
    "                relations.append((entity_id, \"is\", t.text.lower()))\n",
    "            if t.pos_ in (\"ADV\"):\n",
    "                verb = verb_extractor(t).lower()\n",
    "                relations.append((entity_id, verb, t.text.lower()))\n",
    "    return relations\n",
    "\n",
    "extract_ad_relations(\"balls\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_detector(token):\n",
    "    head = token.head\n",
    "    try:\n",
    "        while head.pos_ != \"VERB\":\n",
    "            if head == head.head:\n",
    "                return False\n",
    "            head = head.head\n",
    "        for token in head.children:\n",
    "            if token.dep_ == \"neg\":\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def verb_extractor(token):\n",
    "    head = token.head\n",
    "    try:\n",
    "        while head.pos_ != \"VERB\":\n",
    "            if head == head.head:\n",
    "                return None\n",
    "            head = head.head\n",
    "        return head.text\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_nounchunk_relations(entity_id, text):\n",
    "    doc = nlp(text)\n",
    "    relations = []\n",
    "    for n in doc.noun_chunks:\n",
    "        noun_chunk = []\n",
    "        if not negation_detector(n.root):\n",
    "            for t in n:\n",
    "                if not t.is_stop:\n",
    "                    noun_chunk.append(t.text.lower())\n",
    "            relations.append((entity_id, \"has\", \" \".join(noun_chunk)))\n",
    "    return relations\n",
    "\n",
    "\n",
    "def extract_ad_relations(entity_id, text):\n",
    "    doc = nlp(text)\n",
    "    relations = []\n",
    "    for t in doc:\n",
    "        if not negation_detector(t):\n",
    "            if t.pos_ in (\"ADJ\"):\n",
    "                relations.append((entity_id, \"is\", t.text.lower()))\n",
    "            if t.pos_ in (\"ADV\"):\n",
    "                verb = verb_extractor(t).lower()\n",
    "                relations.append((entity_id, verb, t.text.lower()))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't really work.\n",
    "class NounChunks:\n",
    "    def __init__(self, doc):\n",
    "        self.doc = doc\n",
    "        self.details_list = self.generate_details_list()\n",
    "        self.roots = self.generate_roots()\n",
    "        self.values = self.generate_values()\n",
    "        self.spans = self.generate_spans()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_noun_chunk_details(noun_chunk):\n",
    "        details = {}\n",
    "        details[\"root\"] = noun_chunk.root\n",
    "        details[\"span\"] = list(range(noun_chunk.start, noun_chunk.end))\n",
    "        details[\"text\"] = noun_chunk.text\n",
    "        return details\n",
    "        \n",
    "    def generate_details_list(self):\n",
    "        details_list = []\n",
    "        for n in doc.noun_chunks:\n",
    "            details_list.append(\n",
    "                self.extract_noun_chunk_details(n)\n",
    "            )\n",
    "        return details_list\n",
    "    def generate_roots(self):\n",
    "        roots = []\n",
    "        for d in self.details_list:\n",
    "            roots.append(d[\"root\"])\n",
    "        return roots\n",
    "    def generate_spans(self):\n",
    "        spans = []\n",
    "        for d in self.details_list:\n",
    "            spans += d[\"span\"]\n",
    "        return spans\n",
    "    def generate_values(self):\n",
    "        values = []\n",
    "        for d in self.details_list:\n",
    "            values.append(d[\"text\"])\n",
    "        return values\n",
    "    def generate_relations(self, entity_id):\n",
    "        relations = []\n",
    "        for n in self.doc.noun_chunks:\n",
    "            if n.root.head.i in self.spans:\n",
    "                base_relation = n.root.head.head\n",
    "                relation = [n.root.head.head.text]\n",
    "            else:\n",
    "                base_relation = n.root.head\n",
    "                relation = [n.root.head.text]\n",
    "            if base_relation.dep_ == \"prep\" and base_relation.head.pos_ == \"VERB\":\n",
    "                relation.append(base_relation.head.text)\n",
    "            relation.reverse()\n",
    "            relation = \" \".join(relation)\n",
    "            relations.append(relation.lower())\n",
    "        relations_dict = {}\n",
    "        relations_dict[\"entity_id\"] = entity_id\n",
    "        relations_dict[\"relation\"] = relations\n",
    "        relations_dict[\"value\"] = self.values\n",
    "        relations_df = pd.DataFrame().from_dict(relations_dict)\n",
    "        return relations_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "875527\nIf The Boxer doesn't quite score a knockout, that's because of such flaws as the too-sketchy development of the character of Maggie's son, who turns out to be pivotal. But the movie carries the day by aiming its strongest punches straight at the heart.\n      entity_id    relation                        value\n0   m/the_boxer       score                    The Boxer\n1   m/the_boxer       score                   a knockout\n2   m/the_boxer  's because                   such flaws\n3   m/the_boxer          as  the too-sketchy development\n4   m/the_boxer          of                the character\n5   m/the_boxer          of                 Maggie's son\n6   m/the_boxer       turns                          who\n7   m/the_boxer     carries                    the movie\n8   m/the_boxer     carries                      the day\n9   m/the_boxer      aiming        its strongest punches\n10  m/the_boxer   aiming at                    the heart\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(1, len(review_df))\n",
    "entity_id = review_df.iloc[i][\"entity_id\"]\n",
    "doc = nlp(review_df.iloc[i][\"text\"])\n",
    "nounchunks = NounChunks(doc)\n",
    "relations_df = nounchunks.generate_relations(entity_id)\n",
    "print(i)\n",
    "print(doc.text)\n",
    "print(relations_df)\n",
    "# 808526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the False\nmovie False\nwas False\nbad False\nbut False\nit True\ndefinitely True\ndid True\nnot True\nsuck False\n. True\n"
     ]
    }
   ],
   "source": [
    "for t in nlp(\"the movie was bad but it definitely did not suck.\"):\n",
    "    print(t.text, negation_detector(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_detector(token):\n",
    "    head = token.head\n",
    "    try:\n",
    "        while head.pos_ != \"VERB\":\n",
    "            head = head.head\n",
    "        for token in head.children:\n",
    "            if token.dep_ == \"neg\":\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NounChunks(doc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    entity_id    relation                               value\n",
       "0  dumb_movie  feels like                             a relic\n",
       "1  dumb_movie  feels like               a sad, weak swan song\n",
       "2  dumb_movie          of  cinema's most legendary filmmakers"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity_id</th>\n      <th>relation</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dumb_movie</td>\n      <td>feels like</td>\n      <td>a relic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dumb_movie</td>\n      <td>feels like</td>\n      <td>a sad, weak swan song</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dumb_movie</td>\n      <td>of</td>\n      <td>cinema's most legendary filmmakers</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "n.generate_relations(\"dumb_movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a relic like prep Feels\na sad, weak swan song relic pobj like\ncinema's most legendary filmmakers of prep one\n"
     ]
    }
   ],
   "source": [
    "for n in doc.noun_chunks:\n",
    "    print(n.text, n.root.head.text, n.root.head.dep_, n.root.head.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feels ROOT VERB\nlike prep ADP\na det DET\nrelic pobj NOUN\n, punct PUNCT\na det DET\nsad amod ADJ\n, punct PUNCT\nweak amod ADJ\nswan compound NOUN\nsong appos NOUN\nfrom prep ADP\none pobj NUM\nof prep ADP\ncinema poss NOUN\n's case PART\nmost advmod ADV\nlegendary amod ADJ\nfilmmakers pobj NOUN\n. punct PUNCT\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t.text, t.dep_, t.pos_)\n"
   ]
  }
 ]
}