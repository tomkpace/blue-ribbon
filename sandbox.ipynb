{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "63d0a0a306d17f9618fcd2df71f8943413e3c03229e5631c7d32ac919a8133cf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from relation_extractor import RelationExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(\"raw_data/movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I noticed that there were duplicate entries for certain \n",
    "movies that were released in separate origins.  This \n",
    "removes those duplicates so we can use the rotten_tomatoes_link\n",
    "as the primary index of the data.\n",
    "\"\"\"\n",
    "duplicates = movie_data.groupby(\"rotten_tomatoes_link\").count() \\\n",
    "    .loc[np.any(movie_data.groupby(\"rotten_tomatoes_link\") \\\n",
    "    .count() > 1, axis=1)].index\n",
    "\n",
    "dup_indices = movie_data.loc[(movie_data[\"rotten_tomatoes_link\"].isin(duplicates)) & \\\n",
    "    (movie_data[\"Origin/Ethnicity\"] != \"American\")].index\n",
    "\n",
    "movie_data = movie_data.loc[~movie_data.index.isin(dup_indices)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_column(input_df, column_name, new_column_name):\n",
    "    \"\"\"\n",
    "    Function that will expand the string columns that have \n",
    "    values separated by commas.\n",
    "    \"\"\"\n",
    "    df = input_df.copy(deep=True)\n",
    "    exploded_df = df[column_name].astype(str) \\\n",
    "        .apply(lambda x: x.split(\",\")).explode() \\\n",
    "        .to_frame().rename(columns={column_name: new_column_name})\n",
    "    df = df.merge(exploded_df[[new_column_name]], left_index=True, right_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_columns = {\n",
    "    \"genres\": \"genre\",\n",
    "    \"directors\": \"director\",\n",
    "    \"authors\": \"author\",\n",
    "    \"actors\": \"actor\"\n",
    "}\n",
    "\n",
    "exploded_dfs = {}\n",
    "for c in explode_columns.keys():\n",
    "    exploded_dfs[c] = explode_column(movie_data, c, explode_columns[c])\n",
    "for c in exploded_dfs.keys():\n",
    "    movie_data = movie_data.merge(\n",
    "        exploded_dfs[c][[explode_columns[c]]], left_index=True, right_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {\n",
    "    \"rotten_tomatoes_link\":\"rtLink\",\n",
    "    \"Title\":\"hasTitle\",\n",
    "    \"director\":\"directedBy\",\n",
    "    \"author\":\"authoredBy\",\n",
    "    \"actor\":\"featuredActor\",\n",
    "    \"genre\":\"hadGenre\",\n",
    "    \"Release Year\":\"releasedOn\",\n",
    "    \"production_company\":\"producedBy\",\n",
    "}\n",
    "relations = []\n",
    "for r in relation_dict:\n",
    "    relations.append(relation_dict[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df = movie_data.rename(columns=relation_dict)[relations] \\\n",
    "    .drop_duplicates() \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df.to_csv(\"data/tabular_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_review_df = pd.read_csv(\"raw_data/rotten_tomatoes_critic_reviews.csv\")\n",
    "raw_review_df = raw_review_df.loc[raw_review_df[\"review_content\"].astype(str) != 'nan'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"The Intruder ... is exhilarating and exhausting, the kind of picture you don't bounce back from immediately.\""
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "raw_review_df[raw_review_df[\"top_critic\"] == True].iloc[500][\"review_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = raw_review_df.iloc[0][\"review_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A fantasy adventure that fuses Greek mythology to contemporary American places and values. Anyone around 15 (give or take a couple of years) will thrill to the visual spectacle\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"It is not a fantasy adventure that fuses Greek mythology to contemporary American places and values.\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationExtractor():\n",
    "    \n",
    "    \n",
    "    def __init__(self, entity_id, doc):\n",
    "        self.entity_id = entity_id\n",
    "        self.doc = doc \n",
    "        self.relations = self.extract()\n",
    "\n",
    "\n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Function that extracts a set of triples from the \n",
    "        Spacy doc object in the form [(triple), (triple), ...]\n",
    "        \"\"\"\n",
    "        triples = []\n",
    "        triples += self.extract_location_relation(self.entity_id, self.doc)\n",
    "        return triples\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_location_relation(entity_id, doc):\n",
    "        triples = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"GPE\":\n",
    "                triple = (entity_id, \"hasLocationTheme\", ent.text)\n",
    "                triples.append(triple)\n",
    "        return triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 998/998 [00:00<00:00, 315kB/s]\n",
      "Downloading: 100%|██████████| 1.33G/1.33G [01:18<00:00, 17.0MB/s]\n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 821kB/s] \n",
      "Downloading: 100%|██████████| 60.0/60.0 [00:00<00:00, 20.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The film was set in New York City but not in London and it had Charles de Gaul in it.\"\n",
    "t = ner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ner_output(ner_output):\n",
    "    \"\"\"\n",
    "    Function that processes the Hugging Face NER output into\n",
    "    a list of tuples, [(entity: entity_type), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    def _combine_tokens(token_list):\n",
    "        \"\"\"\n",
    "        Function that combines a list of tokens that may contain\n",
    "        subwords (and ##) into a single phrase.\n",
    "        \"\"\"\n",
    "        ent = \"\"\n",
    "        for t in token_list:\n",
    "            if \"#\" in t:\n",
    "                ent = ent[:len(ent)-1]\n",
    "                ent += f\"{t.replace('#', '')} \"\n",
    "            else:\n",
    "                ent += f\"{t} \"\n",
    "        return ent\n",
    "\n",
    "    i0 = 0\n",
    "    entity = []\n",
    "    entity_type = set()\n",
    "    entity_list = []\n",
    "    entity_type_list = []\n",
    "    for i in ner_output:\n",
    "        if i[\"index\"] > i0 + 1:\n",
    "            if len(entity) > 0:\n",
    "                entity_list.append(entity)\n",
    "                entity_type_list.append(entity_type)\n",
    "            entity = []\n",
    "            entity_type = set()\n",
    "        i0 = i[\"index\"]\n",
    "        entity.append(i[\"word\"])\n",
    "        entity_type.add(i[\"entity\"])\n",
    "    if len(entity) > 0:\n",
    "        entity_list.append(entity)\n",
    "        entity_type_list.append(entity_type)\n",
    "    results = []\n",
    "    for i, raw_ent in enumerate(entity_list):\n",
    "        ent = _combine_tokens(raw_ent)\n",
    "        raw_ent_type = next(iter(entity_type_list[i]))\n",
    "        result = (ent, raw_ent_type.replace(\"I-\", \"\"))\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'word': 'Um', 'score': 0.9985164999961853, 'entity': 'I-PER', 'index': 1},\n",
       " {'word': '##a', 'score': 0.9963938593864441, 'entity': 'I-PER', 'index': 2},\n",
       " {'word': 'T', 'score': 0.999076247215271, 'entity': 'I-PER', 'index': 3},\n",
       " {'word': '##hur', 'score': 0.9789679646492004, 'entity': 'I-PER', 'index': 4},\n",
       " {'word': '##man', 'score': 0.9777899384498596, 'entity': 'I-PER', 'index': 5},\n",
       " {'word': 'Me', 'score': 0.9844141006469727, 'entity': 'I-PER', 'index': 7},\n",
       " {'word': '##dus', 'score': 0.8264440298080444, 'entity': 'I-PER', 'index': 8},\n",
       " {'word': '##a', 'score': 0.9489302635192871, 'entity': 'I-PER', 'index': 9}]"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "ner(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('Greek ', 'MISC'), ('American ', 'MISC')]\n",
      "[('Uma Thurman ', 'PER'), ('Medusa ', 'PER')]\n",
      "[('Harry Potter ', 'MISC')]\n",
      "[('The Lightning Thief ', 'MISC'), ('Potter ', 'PER')]\n",
      "[('The Lightning Thief ', 'MISC'), ('Hogwarts ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC'), ('Chris Columbus ', 'PER')]\n",
      "[('Percy Jackson ', 'MISC'), ('Greek ', 'MISC'), ('Disney Channel ', 'MISC')]\n",
      "[('Columbus ', 'PER')]\n",
      "[('Rick Riordan ', 'PER'), ('Percy Jackson and the Olympians ', 'MISC'), ('Harry Potter ', 'MISC')]\n",
      "[('Chris Columbus ', 'PER'), ('Rick Riordan ', 'PER')]\n",
      "[('Chris Columbus ', 'PER')]\n",
      "[('Percy Jackson ', 'PER'), ('Harry Potter ', 'MISC')]\n",
      "[('British ', 'MISC')]\n",
      "[('Riordan ', 'MISC')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Percy Jackson ', 'PER'), ('Harry Potter ', 'MISC')]\n",
      "[('Medusa ', 'MISC')]\n",
      "[('Rick Riordan ', 'PER'), ('Chris Columbus ', 'PER')]\n",
      "[('The Lightning Thief ', 'MISC')]\n",
      "[('Harry Potter ', 'PER')]\n",
      "[('Columbus ', 'PER')]\n",
      "[('Harry Potter ', 'MISC'), ('Lord of the Rings ', 'MISC')]\n",
      "[('Percy Jackson & the Olympians ', 'ORG'), ('Otis Redding ', 'PER'), ('Harry Potter ', 'MISC')]\n",
      "[('Potter ', 'PER'), ('Ray Harryhausen ', 'PER')]\n",
      "[('Columbus ', 'PER')]\n",
      "[('Lightning Thief ', 'MISC')]\n",
      "[('Columbus ', 'PER'), ('Eragon ', 'MISC'), ('Inkheart ', 'MISC')]\n",
      "[('Lightning Thief ', 'MISC'), ('Grecian ', 'MISC')]\n",
      "[('Chris Columbus ', 'PER'), ('Ray Harryhausen ', 'PER'), ('Jason and the Argonauts ', 'MISC')]\n",
      "[('Percy Jackson and the Olympians ', 'ORG'), ('70s ', 'MISC')]\n",
      "[('Uma Thurman ', 'PER'), ('Pierce Brosnan ', 'PER')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Uma Thurman ', 'PER'), ('Medusa ', 'MISC')]\n",
      "[('Percy Jackson ', 'PER')]\n",
      "[('Lightning Thief ', 'MISC'), ('Columbus ', 'PER'), ('Harry Potter ', 'MISC')]\n",
      "[('Percy Jackson ', 'MISC')]\n",
      "[('Chris Columbus ', 'PER'), ('Harry Potter and the Chamber of Secrets ', 'MISC')]\n",
      "[('Potteres ', 'MISC'), ('Potteres ', 'MISC')]\n",
      "[('C ', 'MISC'), ('Harry Potter ', 'MISC')]\n",
      "[('Columbus ', 'PER'), ('Deep Discount ', 'MISC')]\n",
      "[('Percy Jackson ', 'PER'), ('Harry Potter ', 'PER')]\n",
      "[('Jackson ', 'PER'), ('Harry Potter ', 'MISC')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC'), ('Clash of the Titans ', 'MISC'), ('Greek ', 'MISC'), ('Potter ', 'PER')]\n",
      "[('Greek ', 'MISC'), ('Logan Lerman ', 'PER'), ('Percy Jackson & The Olympians ', 'ORG')]\n",
      "[('Harry ', 'PER'), ('Ron ', 'PER'), ('Hermione ', 'PER'), ('Percy Jackson ', 'PER')]\n",
      "[('Percy ', 'PER')]\n",
      "[('Rummikub ', 'MISC'), ('iPhone ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC')]\n",
      "[('Potter ', 'PER')]\n",
      "[('Potter ', 'PER'), ('Harry ', 'PER')]\n",
      "[('Uma Thurman ', 'PER'), ('Medusa ', 'MISC')]\n",
      "[('Columbus ', 'PER')]\n",
      "[('Lerman ', 'PER')]\n",
      "[('X - Men ', 'MISC'), ('Greek ', 'MISC')]\n",
      "[('Columbus ', 'PER'), ('PG ', 'MISC')]\n",
      "[('Apple ', 'MISC'), ('iPhone ', 'MISC'), ('Fantasy ', 'MISC')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Percy Jackson and the Lightening Thief ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC'), ('Greek ', 'MISC')]\n",
      "[('Percy Jackson & the Olympians ', 'MISC'), ('Columbus ', 'PER'), ('Harry Potter ', 'MISC')]\n",
      "[('Chris Columbus ', 'PER'), ('Columbus ', 'PER')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Pierce Brosnan ', 'PER'), ('Centaur ', 'MISC'), ('Steve Coogan ', 'PER'), ('Hades ', 'PER'), ('Hollywood ', 'LOC')]\n",
      "[('Harry Potter ', 'MISC')]\n",
      "[('Percy Jackson ', 'PER'), ('Greek ', 'MISC')]\n",
      "[('JK Rowling ', 'PER')]\n",
      "[('Clash Of The Titans ', 'MISC'), ('Jackson ', 'PER'), ('Lerman ', 'PER')]\n",
      "[('Potter ', 'PER'), ('Las Vegas ', 'LOC')]\n",
      "[('Hogwarts ', 'MISC')]\n",
      "[('Greek Myth ', 'MISC')]\n",
      "[('Potter ', 'PER')]\n",
      "[('American ', 'MISC')]\n",
      "[('Chris Columbus ', 'PER'), ('Rick Riordan ', 'PER')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Harry Potter ', 'PER'), ('Greek ', 'MISC')]\n",
      "[('Greek ', 'MISC'), ('Gen - Y ', 'MISC')]\n",
      "[('Uma Thurman ', 'PER'), ('Medusa ', 'PER'), ('Steve Coogan ', 'PER')]\n",
      "[('Medusa ', 'ORG'), ('Parthenon ', 'LOC'), ('Nashville ', 'LOC')]\n",
      "[('Percy Jackson ', 'MISC')]\n",
      "[('Ray Harryhausen ', 'PER')]\n",
      "[('Trojan Horse ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC')]\n",
      "[('Harry Potter ', 'MISC'), ('Greek ', 'MISC')]\n",
      "[('Potter ', 'PER')]\n",
      "[('Greek ', 'MISC'), ('Clash of the Titans ', 'MISC')]\n",
      "[('P ', 'MISC'), ('Columbus ', 'PER'), ('Potter ', 'PER'), ('Riordan ', 'PER')]\n",
      "[('Percy Jackson & the Olympians ', 'MISC'), ('The Lightning Thief ', 'MISC')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('Percy Jackson ', 'PER'), ('Eragon ', 'MISC')]\n",
      "[('Percy Jackson & the Olympians ', 'MISC'), ('The Lightning Thief ', 'MISC')]\n",
      "[('Greek ', 'MISC')]\n",
      "[('The Lightning Thief ', 'MISC')]\n",
      "[('Holofcener ', 'PER'), ('Please Give ', 'MISC')]\n",
      "[('Rohmer ', 'MISC')]\n",
      "[('Keener ', 'PER'), ('Peet ', 'PER'), ('Hall ', 'PER')]\n",
      "[('Manhattan ', 'LOC')]\n",
      "[('Holofcener ', 'PER'), ('Sex and the City ', 'MISC')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Nicole Holofcener ', 'PER')]\n",
      "[('Catherine Keener ', 'PER')]\n",
      "[('Holofcener ', 'PER'), ('Keener ', 'PER')]\n",
      "[('Holofcener ', 'PER'), ('Woody Allen ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Manhattan ', 'LOC')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Keener ', 'PER'), ('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Keener ', 'PER'), ('Peet ', 'PER'), ('Hall ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('American ', 'MISC'), ('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Holofcener ', 'PER'), ('Manhattan ', 'LOC'), ('Woody Allen ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Sex and the City 2 ', 'MISC'), ('Holofcener ', 'PER'), ('WWII ', 'MISC'), ('America ', 'LOC')]\n",
      "[('Please Give ', 'MISC'), ('Eric Rohmer ', 'PER'), ('Woody Allen ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Rebecca Hall ', 'PER'), ('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Holofcener ', 'PER'), ('Keener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'ORG')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Woody Allen ', 'PER')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Keener ', 'PER'), ('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Give ', 'ORG')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Holofcener ', 'PER'), ('Keener ', 'PER')]\n",
      "[('Keener ', 'PER'), ('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'ORG')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER'), ('Keener ', 'PER'), ('Hall ', 'PER'), ('Sarah Steele ', 'PER'), ('Kate ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Rebecca Hall ', 'PER'), ('British ', 'MISC')]\n",
      "[('Nicole Holofcener ', 'PER'), ('Please Give ', 'MISC')]\n",
      "[('The Back - Up Plan ', 'MISC'), ('Killers ', 'MISC')]\n",
      "[('Upper East Side ', 'LOC')]\n",
      "[('Nicole Holofcener ', 'PER'), ('Please Give ', 'MISC')]\n",
      "[('of ', 'MISC')]\n",
      "[('Guilbert ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Nicole Holofcener ', 'PER'), ('Transformers ', 'ORG')]\n",
      "[('Please Give ', 'MISC'), ('Friends with Money ', 'MISC')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC'), ('Holofcener ', 'MISC')]\n",
      "[('Keener ', 'PER'), ('Holofcener ', 'PER'), ('American ', 'MISC')]\n",
      "[('Nicole Holofcener ', 'PER'), ('New Yorker ', 'MISC')]\n",
      "[('Keener ', 'PER'), ('Holofcener ', 'PER'), ('Please Give ', 'MISC')]\n",
      "[('Nicole Holofcener ', 'PER'), ('Catherine Keener ', 'PER'), ('Please Give ', 'MISC')]\n",
      "[('Catherine Keener ', 'PER'), ('Kate ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Keener ', 'PER'), ('Kate ', 'PER')]\n",
      "[('Nicole Holofcener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('Holofcener ', 'PER')]\n",
      "[('Nicole Holofcener ', 'PER'), ('Kipling ', 'PER')]\n",
      "[('American ', 'MISC'), ('Richard Linklater ', 'PER'), ('Nicole Holofcener ', 'PER'), ('The Moment ', 'MISC')]\n",
      "[('Holofcener ', 'PER'), ('Peet ', 'PER'), ('Keener ', 'PER')]\n",
      "[('Please Give ', 'MISC')]\n",
      "[('10 ', 'MISC')]\n",
      "[('Dudley Moore ', 'PER')]\n",
      "[('10 ', 'MISC')]\n",
      "[('Blake Edwards ', 'PER'), ('10 ', 'MISC')]\n",
      "[('Blake Edwards ', 'PER'), ('Bo Derek ', 'PER'), ('Bo ', 'PER')]\n",
      "[('Dudley Moore ', 'PER'), ('Julie Andrews ', 'PER'), ('Bo Derek ', 'PER')]\n",
      "[('10 ', 'MISC')]\n",
      "[('Reginald Rose ', 'PER'), ('Lumet ', 'PER')]\n",
      "[('12 Angry Men ', 'MISC')]\n",
      "[('12 Angry Men ', 'MISC'), ('Lumet ', 'PER'), ('The Verdict ', 'MISC')]\n",
      "[('Sidney Lumet ', 'PER')]\n",
      "[('12 Angry Men ', 'MISC')]\n",
      "[('Lumet ', 'PER')]\n",
      "[('Sidney Lumet ', 'PER'), ('Oscar ', 'MISC'), ('Henry Fonda ', 'PER'), ('Martin Balsam ', 'PER'), ('Ed Begley ', 'PER'), ('Jack Warden ', 'PER'), ('E ', 'PER'), ('G . Marshall ', 'PER')]\n",
      "[('12 Angry Men ', 'MISC')]\n",
      "[('Rose ', 'PER'), ('Sidney Lumet ', 'PER')]\n",
      "[('Henry Fonda ', 'PER')]\n",
      "[('Lumet ', 'PER')]\n",
      "[('Sidney Lumet ', 'PER')]\n",
      "[('Lumet ', 'PER')]\n",
      "[('Lumet ', 'PER')]\n",
      "[('Sidney Lumet ', 'PER'), ('12 Angry Men ', 'MISC')]\n",
      "[('Hollywood ', 'LOC'), ('Reginald Rose ', 'PER')]\n",
      "[('12 Angry Men ', 'MISC')]\n",
      "[('Reginald Rose ', 'PER')]\n",
      "[('Disney ', 'PER')]\n",
      "[('Disney ', 'ORG')]\n",
      "[('Disney ! ', 'MISC')]\n",
      "[('20 , 000 Leagues ', 'MISC')]\n",
      "[('20 , 000 Leagues ', 'MISC'), ('The Matrix ', 'MISC'), ('Verne ', 'MISC')]\n",
      "[('20 , 000 Leagues ', 'MISC'), ('Jaws ', 'MISC'), ('The Thing ', 'MISC')]\n",
      "[('Walt Disney ', 'PER'), ('Jules Verne ', 'MISC'), ('20 , 000 Leagues Under the Sea ', 'MISC')]\n",
      "[('Disney World ', 'LOC')]\n",
      "[('Disney ', 'ORG')]\n",
      "[('Walt Disney ', 'PER'), ('20000 Leagues under the Sea ', 'MISC')]\n",
      "[('Disney ', 'ORG')]\n",
      "[('20 , 000 Leagues Under the Sea ', 'MISC'), ('Disney Studios ', 'ORG')]\n",
      "[('James Mason ', 'PER'), ('Captain Nemo ', 'PER'), ('Mason ', 'PER')]\n",
      "[('David Fincher ', 'MISC')]\n",
      "[('Kirk Douglas ', 'PER')]\n",
      "[('Emmerich ', 'PER'), ('Mel Gibson ', 'PER'), ('Apocalypto ', 'MISC')]\n",
      "[('Roland Emmerich ', 'PER')]\n",
      "[('Emmerich ', 'PER'), ('27 Dresses ', 'MISC'), ('Over Her Dead Body ', 'MISC')]\n",
      "[('King Kong ', 'MISC')]\n",
      "[('Emmerich ', 'PER'), ('B ', 'ORG'), ('C ', 'ORG')]\n",
      "[('10 , 000 B ', 'MISC'), ('C ', 'MISC')]\n",
      "[('Roland Emmerich ', 'PER'), ('10 , 000 B ', 'MISC'), ('C . ', 'MISC')]\n",
      "[('C ', 'MISC'), ('Geico ', 'ORG')]\n",
      "[('BC ', 'MISC')]\n",
      "[('Emmerich ', 'PER')]\n",
      "[('Hollywood ', 'MISC'), ('Paleolithic ', 'MISC')]\n",
      "[('10 , 000 BC ', 'MISC')]\n",
      "[('BC ', 'MISC')]\n",
      "[(\"April Fool ' s Day \", 'MISC')]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-5b8340294463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_review_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"review_content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_ner_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m                         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_tensor_on_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1470\u001b[1;33m                         \u001b[0mentities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1471\u001b[0m                         \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1537\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1539\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1540\u001b[0m         )\n\u001b[0;32m   1541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m         )\n\u001b[0;32m    850\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    481\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m                 )\n\u001b[0;32m    485\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m         )\n\u001b[0;32m    404\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         )\n\u001b[0;32m    341\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    t = raw_review_df.iloc[i][\"review_content\"]\n",
    "    p = process_ner_output(ner(t))\n",
    "    if len(p) > 0:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'word': 'New', 'score': 0.9996168613433838, 'entity': 'I-LOC', 'index': 6} 6 0\n{'word': 'York', 'score': 0.9995555877685547, 'entity': 'I-LOC', 'index': 7} 7 6\n{'word': 'City', 'score': 0.9994433522224426, 'entity': 'I-LOC', 'index': 8} 8 7\n{'word': 'London', 'score': 0.9996890425682068, 'entity': 'I-LOC', 'index': 12} 12 8\n{'word': 'Charles', 'score': 0.9985857605934143, 'entity': 'I-PER', 'index': 16} 16 12\n{'word': 'de', 'score': 0.9957852959632874, 'entity': 'I-PER', 'index': 17} 17 16\n{'word': 'G', 'score': 0.9800652265548706, 'entity': 'I-PER', 'index': 18} 18 17\n{'word': '##aul', 'score': 0.9558916091918945, 'entity': 'I-PER', 'index': 19} 19 18\n"
     ]
    }
   ],
   "source": [
    "i0 = 0\n",
    "entity = []\n",
    "entity_list = []\n",
    "for i in t:\n",
    "    print(i, i[\"index\"], i0)\n",
    "    if i[\"index\"] > i0 + 1:\n",
    "        entity_list.append(entity)\n",
    "        entity = []\n",
    "    i0 = i[\"index\"]\n",
    "    entity.append(i[\"word\"])\n",
    "entity_list.append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[], ['New', 'York', 'City'], ['London'], ['Charles', 'de', 'G', '##aul']]"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = entity_list[3]\n",
    "ent = \"\"\n",
    "for w in s:\n",
    "    if \"#\" in w:\n",
    "        ent = ent[:len(ent) - 1]\n",
    "        ent += w.replace(\"#\", \"\")\n",
    "    else:\n",
    "        ent += f\"{w} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Charles de Gaul'"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = raw_review_df.iloc[3]\n",
    "doc = nlp(row[\"review_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Whether audiences will get behind The Lightning Thief is hard to predict. Overall, it's an entertaining introduction to a promising new world -- but will the consuming shadow of Potter be too big to break free of?\nThe Lightning Thief WORK_OF_ART\nPotter GPE\n"
     ]
    }
   ],
   "source": [
    "print(doc)\n",
    "for e in doc.ents:\n",
    "    print(e.text, e.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1017 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1018 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', \"Benicio del Toro's\")]\n",
      "1021 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Romeo')]\n",
      "1035 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan'), ('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Hollywood')]\n",
      "1040 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Prince Valiant')]\n",
      "1045 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Kingdom')]\n",
      "1057 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Western Ireland'), ('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'the Czech Republic')]\n",
      "1058 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'England')]\n",
      "1059 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1062 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Britain')]\n",
      "1065 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1071 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1073 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1082 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1112 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1128 [('m/10004209-tristan_and_isolde', 'hasLocationTheme', 'Tristan')]\n",
      "1133 [('m/10004226-wild_side', 'hasLocationTheme', 'Fassbinder')]\n",
      "1159 [('m/10004288-running_scared', 'hasLocationTheme', 'Wonderland')]\n",
      "1167 [('m/10004288-running_scared', 'hasLocationTheme', 'Running Scared'), ('m/10004288-running_scared', 'hasLocationTheme', 'Running Scared')]\n",
      "1180 [('m/10004288-running_scared', 'hasLocationTheme', 'the Mobius Strip')]\n",
      "1197 [('m/10004288-running_scared', 'hasLocationTheme', 'Running Scared')]\n",
      "1202 [('m/10004288-running_scared', 'hasLocationTheme', 'Vegas')]\n",
      "1210 [('m/10004288-running_scared', 'hasLocationTheme', 'Pulp Fiction')]\n",
      "1227 [('m/10004288-running_scared', 'hasLocationTheme', 'Hollywood')]\n",
      "1236 [('m/10004288-running_scared', 'hasLocationTheme', 'Tarantino directed')]\n",
      "1239 [('m/10004288-running_scared', 'hasLocationTheme', 'Scorcese')]\n",
      "1256 [('m/10004288-running_scared', 'hasLocationTheme', 'Hollywood')]\n",
      "1261 [('m/10004288-running_scared', 'hasLocationTheme', 'Sin City')]\n",
      "1291 [('m/10004504-ultraviolet', 'hasLocationTheme', 'Hong Kong')]\n",
      "1310 [('m/10004504-ultraviolet', 'hasLocationTheme', 'Catwoman')]\n",
      "1334 [('m/10004504-ultraviolet', 'hasLocationTheme', 'Catwoman')]\n",
      "1335 [('m/10004504-ultraviolet', 'hasLocationTheme', 'Tron')]\n",
      "1360 [('m/10004504-ultraviolet', 'hasLocationTheme', 'Hollywood')]\n",
      "1374 [('m/10004635-home_of_the_brave', 'hasLocationTheme', 'Detroit'), ('m/10004635-home_of_the_brave', 'hasLocationTheme', 'Alabama'), ('m/10004635-home_of_the_brave', 'hasLocationTheme', 'Washington')]\n",
      "1378 [('m/10004659-arthur', 'hasLocationTheme', 'Invisibles')]\n",
      "1379 [('m/10004659-arthur', 'hasLocationTheme', 'Pixar')]\n",
      "1380 [('m/10004659-arthur', 'hasLocationTheme', 'Highmore')]\n",
      "1386 [('m/10004659-arthur', 'hasLocationTheme', 'Invisibles')]\n",
      "1394 [('m/10004659-arthur', 'hasLocationTheme', 'Pixar')]\n",
      "1397 [('m/10004659-arthur', 'hasLocationTheme', 'France')]\n",
      "1400 [('m/10004659-arthur', 'hasLocationTheme', 'Minimoy')]\n",
      "1415 [('m/10004659-arthur', 'hasLocationTheme', 'Invisibles')]\n",
      "1418 [('m/10004659-arthur', 'hasLocationTheme', 'France')]\n",
      "1420 [('m/10004659-arthur', 'hasLocationTheme', 'Highmore'), ('m/10004659-arthur', 'hasLocationTheme', 'Finding Neverland')]\n",
      "1422 [('m/10004659-arthur', 'hasLocationTheme', 'Pixar')]\n",
      "1427 [('m/10004659-arthur', 'hasLocationTheme', 'Neverland')]\n",
      "1438 [('m/10004659-arthur', 'hasLocationTheme', 'Highmore')]\n",
      "1439 [('m/10004659-arthur', 'hasLocationTheme', 'Minimoy')]\n",
      "1440 [('m/10004659-arthur', 'hasLocationTheme', 'Pixar'), ('m/10004659-arthur', 'hasLocationTheme', 'Shrek')]\n",
      "1447 [('m/10004659-arthur', 'hasLocationTheme', 'US'), ('m/10004659-arthur', 'hasLocationTheme', 'Japan'), ('m/10004659-arthur', 'hasLocationTheme', 'Highmore'), ('m/10004659-arthur', 'hasLocationTheme', 'Farrow')]\n",
      "1461 [('m/10004659-arthur', 'hasLocationTheme', 'Invisibles')]\n",
      "1472 [('m/10004684-malevolence', 'hasLocationTheme', 'Malevolence')]\n",
      "1475 [('m/10004684-malevolence', 'hasLocationTheme', 'Malevolence')]\n",
      "1476 [('m/10004684-malevolence', 'hasLocationTheme', 'Malevolence')]\n",
      "1507 [('m/10004697-eternal', 'hasLocationTheme', 'Canada')]\n",
      "1521 [('m/10004835-farewell_to_arms', 'hasLocationTheme', 'Hollywood')]\n",
      "1534 [('m/10004925-matador', 'hasLocationTheme', 'Panama'), ('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1535 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan'), ('m/10004925-matador', 'hasLocationTheme', 'Kinnear')]\n",
      "1541 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1559 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1569 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1570 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1572 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1580 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1582 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1583 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1587 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1593 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1598 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1606 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1611 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1619 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1622 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1627 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1631 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1639 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1645 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1651 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1654 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1656 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1664 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1665 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1667 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1669 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1673 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1674 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1676 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1677 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1681 [('m/10004925-matador', 'hasLocationTheme', 'Brosnan'), ('m/10004925-matador', 'hasLocationTheme', 'Brosnan')]\n",
      "1682 [('m/10005057-smile', 'hasLocationTheme', 'Malibu')]\n",
      "1685 [('m/10005057-smile', 'hasLocationTheme', 'Malibu')]\n",
      "1688 [('m/10005057-smile', 'hasLocationTheme', 'China')]\n",
      "1722 [('m/10005178-saint_ralph', 'hasLocationTheme', 'Saint Ralph')]\n",
      "1733 [('m/10005178-saint_ralph', 'hasLocationTheme', 'Rushmore')]\n",
      "1775 [('m/10005178-saint_ralph', 'hasLocationTheme', 'Ralph')]\n",
      "1778 [('m/10005178-saint_ralph', 'hasLocationTheme', 'Canada')]\n",
      "1781 [('m/10005178-saint_ralph', 'hasLocationTheme', 'Canada')]\n",
      "1790 [('m/10005403-the_baxter', 'hasLocationTheme', 'Brooklyn')]\n",
      "1815 [('m/10005403-the_baxter', 'hasLocationTheme', 'Hollywood')]\n",
      "1901 [('m/10005499-oliver_twist', 'hasLocationTheme', 'London')]\n",
      "1928 [('m/10005499-oliver_twist', 'hasLocationTheme', \"Roman Polanski's\")]\n",
      "1985 [('m/10005499-oliver_twist', 'hasLocationTheme', 'London')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,2000):\n",
    "    row = raw_review_df.iloc[i]\n",
    "    entity_id = row[\"rotten_tomatoes_link\"]\n",
    "    doc = nlp(row[\"review_content\"])\n",
    "    t = RelationExtractor(entity_id, doc)\n",
    "    if len(t.relations) > 0:\n",
    "        print(i, t.relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('m/10000_bc', 'hasLocationTheme', 'B.C.')]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "t.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It ***\nIt\na fantasy adventure ***\na\nfantasy\nadventure\nthat\nfuses\nGreek\nmythology\nto\ncontemporary\nAmerican\nplaces\nand\nvalues\nGreek mythology ***\nGreek\nmythology\ncontemporary American places ***\ncontemporary\nAmerican\nplaces\nand\nvalues\nvalues ***\nvalues\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(doc.noun_chunks):\n",
    "    print(token.text, \"***\")\n",
    "    for j in token.subtree:\n",
    "        print(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "def generate_theme_df(movie_data):\n",
    "    theme_df = movie_data[[\"rotten_tomatoes_link\", \"Title\", \"genre\", \"Plot\"]] \\\n",
    "        .drop_duplicates().reset_index(drop=True)\n",
    "    genres = theme_df[\"genre\"].unique()\n",
    "    theme_df[\"indicator\"] = 1\n",
    "    theme_pivot = theme_df \\\n",
    "        .pivot(index=\"rotten_tomatoes_link\", columns=\"genre\", values=\"indicator\") \\\n",
    "        .fillna(0).reset_index()\n",
    "    theme_df = theme_df[[\"rotten_tomatoes_link\", \"Title\", \"Plot\"]] \\\n",
    "        .drop_duplicates().merge(theme_pivot, on=\"rotten_tomatoes_link\") \\\n",
    "        .reset_index(drop=True)\n",
    "    return theme_df\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,3))\n",
    "clf = ExtraTreesClassifier()\n",
    "X = vectorizer.fit_transform(theme_df[\"Plot\"])\n",
    "clf.fit(X, theme_df[\"Comedy\"])\n",
    "importances = clf.feature_importances_\n",
    "names = vectorizer.get_feature_names()"
   ]
  }
 ]
}